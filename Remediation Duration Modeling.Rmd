---
title: 'Final Project: Proposal Phase'
output:
  pdf_document: default
  html_notebook: default
---

```{r}
library(dplyr)
library(lubridate) #for dates
library(VIM) # for missing values
library(naniar) # for missing values
library(corrplot) # for correltation
library(RColorBrewer)
library(gbm) #for boosted trees
library(nnet) # for ANN
library(caret) 
library(ggformula)
```

---
Load-in data
```{r}
ny_env = read.csv("environmental-remediation-sites.csv")
length(unique(ny_env$Program.Number))
```
Begin Data Preparation:
```{r}
#replace blank data with NA's
ny_env<- ny_env %>%
   mutate_all(~replace(., . == "", NA)) 

#convert date to R date format
ny_env$Project.Completion.Date = as.Date(ny_env$Project.Completion.Date)

#filter data for site class
hist_and_current <- ny_env %>%
  filter(Site.Class %in% c("A", "P", "C", "N"))
```

Examine missingness
```{r}
aggr(hist_and_current, numbers=TRUE, sortVars=TRUE, cex.axis=.7, gap=3, 
     ylab=c("Proportion of Missingness","Missingness Pattern"))
gg_miss_fct(hist_and_current, Project.Completion.Date)
gg_miss_var(hist_and_current, show_pct = TRUE)
```

Remove missing data from data set
```{r}
#select columns
hist_and_current <- hist_and_current %>% 
    dplyr::select(-Address2, -Waste.Name, -Owner.Name, -Owner.Address1, -Owner.Address2,-Owner.City, -Owner.State, -Owner.ZIP, -Disposal.Name, -Disposal.Address1, -Disposal.Address2, -Disposal.City, -Disposal.ZIP, -Disposal.State, -Operator.Name, -Operator.Address1, -Operator.Address2, -Operator.City, -Operator.State, -Operator.Zip, -New.York.Zip.Codes.2, -Counties.2,-Georeference, -NYS.Municipal.Boundaries.2, -Address1, -ZIPCode, -Control.Code)
colnames(hist)

hist_and_current <- na.omit(hist_and_current)
dim(hist_and_current)
```

Find first and last action dates and calculate duration of site activities 
```{r}
#get list of unique program numbers from historical data
hist_unique = unique(hist_and_current$Program.Number)

###GET DURATION IN YEARS, MONTHS, DAYS
total_interval = rep(0, length(hist_unique)) 
# for program.number in hist_unique, get max and minimun dates
for (ii in 1:length(hist_unique)) {
  df = hist_and_current[hist_and_current$Program.Number==hist_unique[ii],]
  firstDate = min(df$Project.Completion.Date)
  secondDate = max(df$Project.Completion.Date)
  total_interval[ii] = secondDate-firstDate
}
```

Contaminants:
```{r, include=FALSE}
#### GET ALL CONTAMINANTS FOR EACH SITE
# storage for all contaminants per site
Contaminants.All = vector(mode="list")

unique_Contaminants = unique(hist_and_current$Contaminants)

for (ii in 1:length(hist_unique)) {
    df = hist_and_current[hist_and_current$Program.Number==hist_unique[ii],]
    Contaminants.Site = vector(mode="list")
    for (row in 1:nrow(df)) { # loop over rows of df
      if ((df$Contaminants[row] %in% Contaminants.Site) == FALSE) {
        Contaminants.Site <- c(Contaminants.Site, df$Contaminants[row])
      }
    }
    Contaminants.All[ii] = list(Contaminants.Site)
}


Contaminants.All[which.max(lengths(Contaminants.All))]

```

Bin contaminants
```{r}
#create new bins
asbestos <- c("asbestos")
chemical <- c("acetone","aldrin","alpha-BHC", "antimony","arsenic", "calcium", "calcium carbonate", "cyanides(soluble cyanide salts)",
              "heptachlor epoxide", "hydrogen sulfide", "nitric acid", "potassium", "selenium","sodium","solvents")
metals <- c("barium", "beryllium","cadmium", "chromium", "cobalt", "copper","heavy metals","iron","lead","magnesium","manganese",
            "mercury","metals","nickel","silver","thallium","zinc")
organics <- c("1,1 dichloroethene", "1,1-dichloroethane", "1,1,1-trichloroethane","1,1,1-Trichloroethane(TCA)",
              "1,1,1,2-tetrachloroethane","1,1,2-TCA","1,1,2-trichlorethylene" ,"1,1,2-trichloro-1,2,2-triflouroethane",
              "1,1,2-trichloroethane","1,1,2,2-tetrachloroethane","1,2-dichlorobenzene","1,2-dichloroethane",
              "1,2-dichloroethene","1,2,4-trimethylbenzene", "1,2,4,5-tetrachlorobenzene",
              "1,3-dichlorobenzene","1,3,5-trimethylbenzene","1,3,5-trioxane, 2,4,6-trimethyl-","1,4-dichlorobenzene",
              "1,4-dioxane","2,2,4-trimethylpentane", "1,2,4-trichlorobenzene", "beta-BHC","bromobenzene","bis(2-ethylhexyl)phthalate",
              "butyl benzyl phthalate", "butylbenzene","carbon tetrachloride","chlordane","chlorobenzene","chloroethane", "chloroform",
              "cis-1,2-dichloroethene","cyclohexane", "DDD", "DDE", "DDT", "delta-BHC", "dibenzofuran", "dibutyl phthalate",
              "dichlorodifluoromethane","dichloroethene (1,1-)","dichloroethene (cis-1,2-)","dichloroethene (trans-1,2-)","dieldrin",
              "diethyl phthalate","dimethyl phthalate","dinitrotoluene","endosulfan","endrin","fluorene","formaldehyde","heptane",
              "hexachlorobenzene","hexane","isopropyl alcohol","isopropylbenzene","m-xylene","MEK","methane","methanol","methoxychlor",
              "methyl chloride","methyl ethyl ketone","methyl isobutyl ketone","methylene chloride",
              "n,n-dimethylaniline (n,n-diethyl aniline)","n-propylbenzene", "o-xylene", "p-xylene",  "perchloroethane",
              "Perfluorooctane Sulfonic Acid","perfluorooctanoic acid", "sec-butylbenzene", "styrene","tert-butylbenzene",
              "tetrachloroethane","tetrachloroethene","tetrachloroethene (PCE)","tetrahydrofuran","trans-1,2-dichloroethene",
              "trichloroethene (TCE)","trichloromonofluoromethane","vinyl chloride","vinylidene chloride","volatile organics",
              "aniline","phenol")
PAHs <- c("1,2,4-TMB","acenapthylene","acenaphthene", "anthracene", "benzo(a)anthracene", "benzo(b)fluoranthene",
          "benzo(a)pyrene","benzo(g,h,i)perylene", "benzo(k)fluoranthene","chrysene","coal tar","coal tar pitch volatiles",
          "dibenz[a,h]anthracene","fluoranthene","indeno(1,2,3-CD)pyrene", "m-cresol(s)","naphthalene", "phenanthrene", 
          "polycyclic aromatic hydrocarbons (PAHS), total", "pyrene")
PCBs <- c("PCB  aroclor 1262","PCB aroclor 1016","PCB aroclor 1242","PCB aroclor 1248","PCB aroclor 1254","PCB aroclor 1260",
          "polychlorinated biphenyls (PCB)")
petroleum <- c("benzene","benzene, toluene, ethylbenzene and xylenes (BTEX)","cumene", "ethanol","ethylbenzene",
               "methyl-tert-butyl ether (MTBE)","MTBE (methyl-tert-butyl ether)","petroleum products","toluene","unknown petroleum",
               "xylene (mixed)")

#create Contaminants_new
for (ii in (1:nrow(hist_and_current))) {
  if (hist_and_current$Contaminants[ii] %in% asbestos) {
    hist_and_current$Contaminants_New[ii] = "Asbestos"
  } else if (hist_and_current$Contaminants[ii] %in% chemical) {
    hist_and_current$Contaminants_New[ii] = "Other Chemical"
  } else if (hist_and_current$Contaminants[ii] %in% metals) {
    hist_and_current$Contaminants_New[ii] = "Metals"
  } else if (hist_and_current$Contaminants[ii] %in% PAHs) {
    hist_and_current$Contaminants_New[ii] = "PAHs"
  } else if (hist_and_current$Contaminants[ii] %in% PCBs) {
    hist_and_current$Contaminants_New[ii] = "PCBs"
  } else if (hist_and_current$Contaminants[ii] %in% petroleum) {
    hist_and_current$Contaminants_New[ii] = "Petroleum"
  } else if (hist_and_current$Contaminants[ii] %in% organics) {
    hist_and_current$Contaminants_New[ii] = "Organic Compounds"
  }
}
table(hist_and_current$Contaminants_New)
```



One hot code the new contaminants column. 
```{r}
#one hot encode contaminants
one_hot <- model.matrix(~0+hist_and_current[,'Contaminants_New'])
Contaminants.All = data.frame(one_hot)
#rename columns
names(Contaminants.All) = gsub(pattern = "hist_and_current....Contaminants_New..", replacement = "", x = names(Contaminants.All))
Contaminants.All
```

Summarize the contaminants per site
```{r, include = FALSE}
#link program numbers
Contaminants.All$Program.Number = hist_and_current$Program.Number
#contaminants
contaminant_names = colnames(Contaminants.All[,-8])

#new storage dataframe 
Contaminants.Per.Site = data.frame(matrix(nrow=length(hist_unique), ncol = length(contaminant_names))) 
# assign column names
colnames(Contaminants.Per.Site) = contaminant_names

#loop over Program ID
for (ii in 1:length(hist_unique)) {
    df = Contaminants.All[Contaminants.All$Program.Number==hist_unique[ii],]
    sums = colSums(df[-8])
    for (jj in 1:length(sums)) {  #loop through sums to set contaminant recorded to 1 to record contaminant presence
      if (sums[jj] > 0) {
        sums[jj] <- 1   
      } 
    }
   Contaminants.Per.Site[ii,] = sums
}

#convert to factors
Contaminants.Per.Site <- Contaminants.Per.Site %>%
  mutate_if(is.double, as.factor)
```

One hot encode Control Type
```{r}
#one hot encode control types
unique_Control.Type = unique(hist_and_current$Control.Type)
one_hot <- model.matrix(~0+hist_and_current[,'Control.Type'])
Control.All = data.frame(one_hot)
#rename columns
names(Control.All) = gsub(pattern = "hist_and_current....Control.Type..", replacement = "", x = names(Control.All))

Control.All$Program.Number = hist_and_current$Program.Number
#controls
control_names = colnames(Control.All[,-6])

#new storage dataframe 
Control.Per.Site = data.frame(matrix(nrow=length(hist_unique), ncol = length(control_names))) 
# assign column names
colnames(Control.Per.Site) = control_names

#loop over Program ID
for (ii in 1:length(hist_unique)) {
    df = Control.All[Control.All$Program.Number==hist_unique[ii],]
    sums = colSums(df[-6])
    for (jj in 1:length(sums)) {  #loop through sums to set control to 1 if used on site
      if (sums[jj] > 0) {
        sums[jj] <- 1
      }
    }
    Control.Per.Site[ii,] = sums
}
#convert to factors
Control.Per.Site <- Control.Per.Site %>%
  mutate_if(is.double, as.factor)

```



One hot code Project.Name
```{r}
#one hot encode project.name
one_hot <- model.matrix(~0+hist_and_current[,'Project.Name'])
Project.Name.All = data.frame(one_hot)
#rename columns
names(Project.Name.All) = gsub(pattern = "hist_and_current....Project.Name..", replacement = "", x = names(Project.Name.All))

Project.Name.All$Program.Number = hist_and_current$Program.Number
#contaminants
project_names = colnames(Project.Name.All[,-8])

#new storage dataframe 
Project.Name.Per.Site = data.frame(matrix(nrow=length(hist_unique), ncol = length(project_names))) 
# assign column names
colnames(Project.Name.Per.Site) = project_names

#loop over Program ID
for (ii in 1:length(hist_unique)) {
    df = Project.Name.All[Project.Name.All$Program.Number==hist_unique[ii],]
    sums = colSums(df[-8])
    for (jj in 1:length(sums)) {  #loop through sums to set project to 1 to record if used at site
      if (sums[jj] > 0) {
        sums[jj] <- 1
      }
    }
    Project.Name.Per.Site[ii,] = sums
}
#convert to factors
Project.Name.Per.Site <- Project.Name.Per.Site %>%
  mutate_if(is.double, as.factor)

```


Summarizing additional columns by site
```{r, warning=FALSE}
colnames(hist_and_current)
site_summary = data.frame(matrix(nrow=length(hist_unique), ncol = length(colnames(hist_and_current))))
# assign column names
colnames(site_summary) = colnames(hist_and_current)

#use most recent entry for specific site information
for (ii in 1:length(hist_unique)) {
  df = hist_and_current[hist_and_current$Program.Number==hist_unique[ii],]
  z <- which(df$Project.Completion.Date==max(df$Project.Completion.Date))
  latest_row = df[z,]
  site_summary[ii,] = latest_row
}
```

Drop unnecessary variables and add the column for total inverval elapsed.
```{r}
#drop unhelpful variables 
site_summary <- site_summary %>%
  dplyr::select(-Project.Completion.Date,-Latitude, -Longitude,-Control.Type,-Project.Name,-Contaminants,-Contaminants_New) 
#add duration variable
site_summary$Duration_Total_Days = total_interval
```

Putting it all together in the final data frame
```{r}
#add Program.Number to each dataframe
Control.Per.Site$Program.Number = site_summary$Program.Number
Project.Name.Per.Site$Program.Number = site_summary$Program.Number
Contaminants.Per.Site$Program.Number = site_summary$Program.Number
#merge data frames
final_df = merge(site_summary, Control.Per.Site, by="Program.Number")
final_df = merge(final_df, Project.Name.Per.Site, by="Program.Number")
final_df = merge(final_df, Contaminants.Per.Site, by="Program.Number")

#remove undiagnostic variables
final_df <- final_df %>%
  dplyr::select(-Program.Number,-Program.Facility.Name,-Locality,-County,-SWIS.Code,-OU) %>%#keep just DEC.Region for location
                                              #drop OU since its meaning is not clearly defined in data dictionary) %>%
  #convert variables to factors
  mutate(Program.Type = as.factor(Program.Type),
         DEC.Region = as.factor(DEC.Region))
```


View data and vif. None over 10 so no variables are eliminated.
```{r,}

linear<- lm(Duration_Total_Days ~ .-Site.Class, data=final_df)
car::vif(linear)
final_df
```


Separate the active sites from the completed ones
```{r}
#filter on site class, then drop site class variable
complete_sites <- final_df %>%
  filter(Site.Class %in% c("C", "N")) %>%
  dplyr::select(-Site.Class)
#579 complete sites

#filter on site class, then drop site class variable
active_sites <- final_df %>%
    filter(!(Site.Class %in% c("C", "N"))) %>%
  dplyr::select(-Site.Class)
#27 active sites

```


Prepare data for cross validation
```{r}
#get n
n = dim(complete_sites)[1]

############# Model specifications #############
# Boosted trees
floor(sqrt(NCOL(complete_sites))) #interaction depth max number = 13
boostLambda = seq(.01, 1,.1)
gbmGrid <-  expand.grid(interaction.depth = (1:3), #use smaller interation depth for computational feasibility
                    n.trees = 200,  #use 200 trees (more trees is ideal, but computationally unfeasible)
                    shrinkage = boostLambda, #5 values from .01 to .1 (reasonable, not too computationally demanding)
                    n.minobsinnode = 10) # use default
                    
#ANN 
annLambda = seq(.01,1.1,.1) #lambda vector for decay rate values
#annGrid <-  expand.grid(size = (1:5), # test models with 1 to 5 hidden layers
                    #decay = annLambda) # 10 values from 1 to 2 in increments of .1 

```

Double cross-validation for modeling-process assessment
```{r, warning=FALSE, include=FALSE}
### model assessment OUTER shell 
# produce loops for 5-fold cross-validation for model assessment
nfolds = 5
groups = rep(1:nfolds,length=n)  #produces list of group labels
set.seed(32) #for reproducibility
cvgroups = sample(groups,n)  #orders randomly

# set up storage for predicted values from the double-cross-validation
allpredictedCV = rep(NA,n)
# set up storage to see what models are "best" on the inner loops
allbestTypes = rep(NA,nfolds)
allbestPars = vector("list",nfolds)
allbestModels = vector("list",nfolds)
allbestRSME = rep(NA,nfolds)

# loop through outer splits
for (j in 1:nfolds)  {  
  groupj = (cvgroups == j)
  traindata = complete_sites[!groupj,]
  trainx = model.matrix(Duration_Total_Days ~ ., 
                        data = traindata)[,-1] #omit un-diagnostic variables, and duration intervals except for Total_Days
  trainy = traindata$Duration_Total_Days
  validdata = complete_sites[groupj,]
  validx = model.matrix(Duration_Total_Days ~ ., 
                        data = validdata)[,-1]
  validy = validdata$Duration_Total_Days
  
  #specify data to be used
  dataused=traindata
  
  ###  entire model-fitting process (on traindata only)
  # set up training method
  set.seed(32)
  training = trainControl(method = "cv", number = 5) # 5-fold cv


  # cross-validation of Boosted Tree
  fit_boost = train(Duration_Total_Days ~ .,
                          data = dataused,
                          method = "gbm",
                          trControl = training,
                          tuneGrid = gbmGrid)
  
  # cross-vladiation of ANN
  fit_ANN = train(Duration_Total_Days ~ .,
                 data = dataused,
                 method = "nnet",
                 tuneGrid = expand.grid(size = (1:2), decay = annLambda), #size of 1 for computational feasibility
                 trace = FALSE,
                 preProc = c("center", "scale"),
                 trControl = training)
  
  ### identify selected model to fit to full data 
  all_best_Types = c("Boosted Trees","ANN")
  all_best_Pars = list(fit_boost$bestTune,fit_ANN$bestTune)
  all_best_Models = list(fit_boost$finalModel,
                         fit_ANN$finalModel)
  all_best_RMSE = c(min(fit_boost$results$RMSE),
                    min(fit_ANN$results$RMSE))
  # model counts and types
  mBoost = length(boostLambda)*3 #length of all lambdas times interaction depths
  mANN = length(annLambda)*2 #length of all decay values times hidden layers (2)
  mmodels = mBoost+mANN
  modelMethod = c(rep("Boosted Trees",mBoost),rep("ANN",mANN))
  all_caret_RMSE = c(fit_boost$results$RMSE,
                     fit_ANN$results$RMSE)
  #plot here
  one_best_Type = all_best_Types[which.min(all_best_RMSE)]
  one_best_Pars = all_best_Pars[which.min(all_best_RMSE)]
  one_best_Model = all_best_Models[[which.min(all_best_RMSE)]]
  # store
  allbestTypes[j] = one_best_Type
  allbestPars[[j]] = one_best_Pars
  #store to compare models
  allbestModels[[j]] = one_best_Model
  allbestRSME[j] = min(all_best_RMSE)
  if (one_best_Type == "Boosted Trees") {  # Boosted Trees models
    #bestlambda = one_best_Pars[[1]]$shrinkage
    allpredictedCV[groupj]  = predict(one_best_Model,newdata=validx)
  } else if (one_best_Type == "ANN") { 
    allpredictedCV[groupj] = predict(one_best_Model,validdata)
  }
}
```

Get final model
```{r}
# print individual results
for (j in 1:nfolds) {
  writemodel = paste("The best model at loop", j, 
                     "is of type", allbestTypes[j],
                     "with parameter(s)",allbestPars[[j]])
  print(writemodel, quote = FALSE)
}

#assessment
y = complete_sites$Duration_Total_Days
RMSE = sqrt(mean(allpredictedCV-y)^2); RMSE
R2 = 1-sum((allpredictedCV-y)^2)/sum((y-mean(y))^2); R2


# about 75.0% of the variability in  hour_average_max.power values is 
# explained by this model-fitting process

final_model = allbestModels[[which.min(allbestRSME)]]
final_type = allbestTypes[which.min(allbestRSME)]; final_type
final_pars = allbestPars[[which.min(allbestRSME)]]; final_pars

```

Final model fit to entire dataset. 
```{r}
training = trainControl(method = "none")
finalModelGrid <-  data.frame(interaction.depth = final_pars[[1]]$interaction.depth, 
                    n.trees = final_pars[[1]]$n.trees, 
                    shrinkage = final_pars[[1]]$shrinkage,
                    n.minobsinnode = 10) # use default

 # cross-validation of Boosted Tree
fit_final = train(Duration_Total_Days ~ ., 
                      data = complete_sites,
                      verbose=FALSE,
                      method = "gbm",
                      trControl = training,
                      tuneGrid = finalModelGrid)

summary(fit_final)


```


Figure of optimal lambda for final model (boosted trees)
```{r}
min(fit_boost$results$RMSE)
gf_line(RMSE ~ shrinkage, data = fit_boost$results) %>% gf_refine(coord_cartesian(xlim = c(0, 1), ylim =
c(1100, 1600))) %>%
  gf_vline(xintercept =~ fit_final$finalModel$shrinkage, 
color = "red") %>%
gf_label(0.4 ~ 0.04, label = paste("Optimal lambda \n=", round(fit_final$finalModel$shrinkage, 4)))


```

Making predictions for active sites
```{r}
active_preds = predict(fit_final,active_sites)

active_sites$Duration_Predicted = active_preds
active_sites%>%dplyr::select(Duration_Total_Days,Duration_Predicted) #negative predictions highlight issues with model

```
